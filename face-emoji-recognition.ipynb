{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f6028",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:45.869609Z",
     "iopub.status.busy": "2022-11-14T07:10:45.868725Z",
     "iopub.status.idle": "2022-11-14T07:10:45.875725Z",
     "shell.execute_reply": "2022-11-14T07:10:45.874620Z"
    },
    "papermill": {
     "duration": 0.015752,
     "end_time": "2022-11-14T07:10:45.877886",
     "exception": false,
     "start_time": "2022-11-14T07:10:45.862134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45d63f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:45.888104Z",
     "iopub.status.busy": "2022-11-14T07:10:45.886238Z",
     "iopub.status.idle": "2022-11-14T07:10:51.410735Z",
     "shell.execute_reply": "2022-11-14T07:10:51.409783Z"
    },
    "papermill": {
     "duration": 5.53138,
     "end_time": "2022-11-14T07:10:51.413142",
     "exception": false,
     "start_time": "2022-11-14T07:10:45.881762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import datetime\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0148bde7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:51.422721Z",
     "iopub.status.busy": "2022-11-14T07:10:51.421923Z",
     "iopub.status.idle": "2022-11-14T07:10:51.428812Z",
     "shell.execute_reply": "2022-11-14T07:10:51.427966Z"
    },
    "papermill": {
     "duration": 0.013677,
     "end_time": "2022-11-14T07:10:51.430707",
     "exception": false,
     "start_time": "2022-11-14T07:10:51.417030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2568a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:51.439024Z",
     "iopub.status.busy": "2022-11-14T07:10:51.438285Z",
     "iopub.status.idle": "2022-11-14T07:10:53.936703Z",
     "shell.execute_reply": "2022-11-14T07:10:53.935626Z"
    },
    "papermill": {
     "duration": 2.505318,
     "end_time": "2022-11-14T07:10:53.939477",
     "exception": false,
     "start_time": "2022-11-14T07:10:51.434159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATADIR = \"../input/facial-expression-recog-image-ver-of-fercdataset/Dataset/\"\n",
    "# ../input/facial-expression-recog-image-ver-of-fercdataset/Dataset/test\n",
    "CLASSES = [\"anger\", \"disgust\", \"fear\", \"happiness\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "\n",
    "training_data = []\n",
    "test_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CLASSES:\n",
    "        path = os.path.join(DATADIR, \"train\", category)\n",
    "        class_num = CLASSES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (48, 48))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "def create_test_data():\n",
    "    for category in CLASSES:\n",
    "        path = os.path.join(DATADIR, \"test\", category)\n",
    "        class_num = CLASSES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (48, 48))\n",
    "                test_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "create_training_data()\n",
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73cf826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:53.948309Z",
     "iopub.status.busy": "2022-11-14T07:10:53.947363Z",
     "iopub.status.idle": "2022-11-14T07:10:53.954921Z",
     "shell.execute_reply": "2022-11-14T07:10:53.954065Z"
    },
    "papermill": {
     "duration": 0.01386,
     "end_time": "2022-11-14T07:10:53.956851",
     "exception": false,
     "start_time": "2022-11-14T07:10:53.942991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0dd321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:53.965335Z",
     "iopub.status.busy": "2022-11-14T07:10:53.964659Z",
     "iopub.status.idle": "2022-11-14T07:10:53.971882Z",
     "shell.execute_reply": "2022-11-14T07:10:53.970796Z"
    },
    "papermill": {
     "duration": 0.013493,
     "end_time": "2022-11-14T07:10:53.973880",
     "exception": false,
     "start_time": "2022-11-14T07:10:53.960387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "for features, label in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, 48, 48, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 48, 48, 1)\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcd87ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:53.982286Z",
     "iopub.status.busy": "2022-11-14T07:10:53.981457Z",
     "iopub.status.idle": "2022-11-14T07:10:53.987329Z",
     "shell.execute_reply": "2022-11-14T07:10:53.985952Z"
    },
    "papermill": {
     "duration": 0.0126,
     "end_time": "2022-11-14T07:10:53.989791",
     "exception": false,
     "start_time": "2022-11-14T07:10:53.977191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n",
      "(48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1:])\n",
    "print(X_test.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a73488d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:53.998746Z",
     "iopub.status.busy": "2022-11-14T07:10:53.997780Z",
     "iopub.status.idle": "2022-11-14T07:10:54.006604Z",
     "shell.execute_reply": "2022-11-14T07:10:54.005672Z"
    },
    "papermill": {
     "duration": 0.015151,
     "end_time": "2022-11-14T07:10:54.008638",
     "exception": false,
     "start_time": "2022-11-14T07:10:53.993487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/facial-expression-recog-image-ver-of-fercdataset/Dataset/train/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../input/facial-expression-recog-image-ver-of-fercdataset/Dataset'\n",
    "train_image_files_path = os.path.join(path, \"train/\")\n",
    "valid_image_files_path = os.path.join(path, \"test/\")\n",
    "train_image_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa1e9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:10:54.017280Z",
     "iopub.status.busy": "2022-11-14T07:10:54.016486Z",
     "iopub.status.idle": "2022-11-14T07:11:20.755862Z",
     "shell.execute_reply": "2022-11-14T07:11:20.754952Z"
    },
    "papermill": {
     "duration": 26.752997,
     "end_time": "2022-11-14T07:11:20.765155",
     "exception": false,
     "start_time": "2022-11-14T07:10:54.012158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32298 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "target_size = (img_width, img_height)\n",
    "#training_images = np.expand_dims(training_images, axis=0)\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_image_files_path,  \n",
    "                                                        color_mode = \"grayscale\",\n",
    "                                                        target_size = target_size,\n",
    "                                                        class_mode = 'categorical',\n",
    "#                                                         classes = CLASSES,\n",
    "                                                        seed = 42)\n",
    "test_set = test_datagen.flow_from_directory(valid_image_files_path,\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    target_size = target_size,\n",
    "                                                    class_mode = 'categorical',\n",
    "#                                                     classes = CLASSES,\n",
    "                                                    seed = 42)\n",
    "\n",
    "# test_set = test_datagen.flow_from_directory(\n",
    "#     'C:/Users/anude/Downloads/archive/Dataset/test',\n",
    "#     target_size=(48, 48),\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06413ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:11:20.809307Z",
     "iopub.status.busy": "2022-11-14T07:11:20.802772Z",
     "iopub.status.idle": "2022-11-14T07:11:24.216682Z",
     "shell.execute_reply": "2022-11-14T07:11:24.215367Z"
    },
    "papermill": {
     "duration": 3.430887,
     "end_time": "2022-11-14T07:11:24.219306",
     "exception": false,
     "start_time": "2022-11-14T07:11:20.788419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 07:11:20.964007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:21.131208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:21.132386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:21.133974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 07:11:21.134277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:21.135235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:21.136156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:23.489826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:23.490780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:23.491493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 07:11:23.492116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       131200    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       262272    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       262272    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,315,335\n",
      "Trainable params: 1,314,311\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(48,48,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"linear\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0003), metrics=['accuracy'])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79dcdb86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:11:24.229311Z",
     "iopub.status.busy": "2022-11-14T07:11:24.228863Z",
     "iopub.status.idle": "2022-11-14T07:11:24.236432Z",
     "shell.execute_reply": "2022-11-14T07:11:24.235432Z"
    },
    "papermill": {
     "duration": 0.015037,
     "end_time": "2022-11-14T07:11:24.238877",
     "exception": false,
     "start_time": "2022-11-14T07:11:24.223840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ebfd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T07:11:24.248555Z",
     "iopub.status.busy": "2022-11-14T07:11:24.248283Z",
     "iopub.status.idle": "2022-11-14T07:38:00.206282Z",
     "shell.execute_reply": "2022-11-14T07:38:00.205195Z"
    },
    "papermill": {
     "duration": 1595.965881,
     "end_time": "2022-11-14T07:38:00.209228",
     "exception": false,
     "start_time": "2022-11-14T07:11:24.243347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 07:11:24.521974: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 07:11:26.500074: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010/1010 [==============================] - 161s 152ms/step - loss: 1.7616 - accuracy: 0.3336 - val_loss: 1.5542 - val_accuracy: 0.4294\n",
      "Epoch 2/30\n",
      "1010/1010 [==============================] - 48s 47ms/step - loss: 1.5329 - accuracy: 0.4269 - val_loss: 1.3878 - val_accuracy: 0.4921\n",
      "Epoch 3/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.4037 - accuracy: 0.4783 - val_loss: 1.3111 - val_accuracy: 0.5157\n",
      "Epoch 4/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.3142 - accuracy: 0.5168 - val_loss: 1.2287 - val_accuracy: 0.5486\n",
      "Epoch 5/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.2510 - accuracy: 0.5450 - val_loss: 1.2192 - val_accuracy: 0.5517\n",
      "Epoch 6/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.2082 - accuracy: 0.5638 - val_loss: 1.1470 - val_accuracy: 0.5868\n",
      "Epoch 7/30\n",
      "1010/1010 [==============================] - 47s 47ms/step - loss: 1.1729 - accuracy: 0.5823 - val_loss: 1.1499 - val_accuracy: 0.5784\n",
      "Epoch 8/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.1482 - accuracy: 0.5910 - val_loss: 1.1375 - val_accuracy: 0.5868\n",
      "Epoch 9/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 1.1270 - accuracy: 0.6025 - val_loss: 1.1074 - val_accuracy: 0.6069\n",
      "Epoch 10/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.1102 - accuracy: 0.6051 - val_loss: 1.0920 - val_accuracy: 0.6180\n",
      "Epoch 11/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 1.0993 - accuracy: 0.6155 - val_loss: 1.0793 - val_accuracy: 0.6239\n",
      "Epoch 12/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 1.0861 - accuracy: 0.6221 - val_loss: 1.0726 - val_accuracy: 0.6344\n",
      "Epoch 13/30\n",
      "1010/1010 [==============================] - 47s 47ms/step - loss: 1.0733 - accuracy: 0.6282 - val_loss: 1.1717 - val_accuracy: 0.6055\n",
      "Epoch 14/30\n",
      "1010/1010 [==============================] - 46s 45ms/step - loss: 1.0588 - accuracy: 0.6331 - val_loss: 1.0893 - val_accuracy: 0.6244\n",
      "Epoch 15/30\n",
      "1010/1010 [==============================] - 47s 47ms/step - loss: 1.0451 - accuracy: 0.6413 - val_loss: 1.0738 - val_accuracy: 0.6339\n",
      "Epoch 16/30\n",
      "1010/1010 [==============================] - 47s 47ms/step - loss: 1.0384 - accuracy: 0.6445 - val_loss: 1.0750 - val_accuracy: 0.6317\n",
      "Epoch 17/30\n",
      "1010/1010 [==============================] - 48s 47ms/step - loss: 1.0254 - accuracy: 0.6487 - val_loss: 1.0791 - val_accuracy: 0.6219\n",
      "Epoch 18/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 1.0219 - accuracy: 0.6516 - val_loss: 1.0501 - val_accuracy: 0.6551\n",
      "Epoch 19/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 1.0092 - accuracy: 0.6579 - val_loss: 1.0611 - val_accuracy: 0.6475\n",
      "Epoch 20/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 1.0055 - accuracy: 0.6604 - val_loss: 1.0630 - val_accuracy: 0.6475\n",
      "Epoch 21/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 0.9941 - accuracy: 0.6674 - val_loss: 1.0710 - val_accuracy: 0.6450\n",
      "Epoch 22/30\n",
      "1010/1010 [==============================] - 47s 47ms/step - loss: 0.9901 - accuracy: 0.6703 - val_loss: 1.0786 - val_accuracy: 0.6417\n",
      "Epoch 23/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 0.9856 - accuracy: 0.6730 - val_loss: 1.0540 - val_accuracy: 0.6512\n",
      "Epoch 24/30\n",
      "1010/1010 [==============================] - 46s 45ms/step - loss: 0.9792 - accuracy: 0.6760 - val_loss: 1.0841 - val_accuracy: 0.6408\n",
      "Epoch 25/30\n",
      "1010/1010 [==============================] - 48s 47ms/step - loss: 0.9738 - accuracy: 0.6780 - val_loss: 1.0850 - val_accuracy: 0.6436\n",
      "Epoch 26/30\n",
      "1010/1010 [==============================] - 47s 47ms/step - loss: 0.9688 - accuracy: 0.6813 - val_loss: 1.0605 - val_accuracy: 0.6631\n",
      "Epoch 27/30\n",
      "1010/1010 [==============================] - 48s 47ms/step - loss: 0.9613 - accuracy: 0.6841 - val_loss: 1.1006 - val_accuracy: 0.6447\n",
      "Epoch 28/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 0.9571 - accuracy: 0.6877 - val_loss: 1.0659 - val_accuracy: 0.6615\n",
      "Epoch 29/30\n",
      "1010/1010 [==============================] - 47s 46ms/step - loss: 0.9525 - accuracy: 0.6887 - val_loss: 1.0693 - val_accuracy: 0.6615\n",
      "Epoch 30/30\n",
      "1010/1010 [==============================] - 46s 46ms/step - loss: 0.9473 - accuracy: 0.6907 - val_loss: 1.0487 - val_accuracy: 0.6643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=training_set,\n",
    "                 validation_data=test_set,\n",
    "                 epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81370cd",
   "metadata": {
    "papermill": {
     "duration": 0.982016,
     "end_time": "2022-11-14T07:38:02.170784",
     "exception": false,
     "start_time": "2022-11-14T07:38:01.188768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8144b0a",
   "metadata": {
    "papermill": {
     "duration": 0.929602,
     "end_time": "2022-11-14T07:38:04.085018",
     "exception": false,
     "start_time": "2022-11-14T07:38:03.155416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1650.754203,
   "end_time": "2022-11-14T07:38:08.664950",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-14T07:10:37.910747",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
